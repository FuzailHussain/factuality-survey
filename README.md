# Factuality in Large Language Models: Ongoing Survey Project

This is an **ongoing collection of research papers** related to **factuality in Large Language Models (LLMs)**.

For brevity, individual papers **before 2025** are not listed. Instead, we include two comprehensive survey papers covering those years. The list focuses on **individual 2025 papers** that introduce new contributions beyond what these surveys cover.

---

## Survey Papers (Covers papers before 2025)

### Yuxia Wang et al. (EMNLP 2024)  
**Factuality of Large Language Models: A Survey**  
Comprehensive taxonomy of factual errors, evaluation benchmarks, model behaviors, and mitigation strategies across 2023–2024 work.  
[PDF](https://aclanthology.org/2024.emnlp-main.1088.pdf) | [arXiv](https://arxiv.org/abs/2310.07521)

### Cunxiang Wang et al. (ACM Computing Surveys 2025) covers up to year 2023, although published in 2025  
**Survey on Factuality in Large Language Models: Knowledge, Retrieval, and Domain-Specificity**  
Focuses on knowledge grounding, retrieval-augmented generation, domain-specific challenges, and factual consistency techniques.  
[ResearchGate](https://www.researchgate.net/publication/392349351_Survey_on_Factuality_in_Large_Language_Models)

---

## 2025 Papers (Not covered in the above Surveys)

### FactReasoner: Probabilistic Fact-Level Factuality Assessment for Long-Form LLM Outputs  
**Marinescu et al., Feb 2025**  
- Decomposes outputs into atomic facts and verifies them probabilistically.  
- Enables structured, interpretable factuality scoring.  
[arXiv:2502.18573](https://arxiv.org/abs/2502.18573)

---

### Verify with Caution: The Pitfalls of Relying on Imperfect Factuality Metrics  
**Godbole & Jia, Jan 2025**  
- Empirical audit of 11 metrics across tasks; highlights inconsistencies.  
- Cautions against blind reliance on popular scoring methods.  
[arXiv:2501.14883](https://arxiv.org/abs/2501.14883)

---

### Are the Hidden States Hiding Something? Investigating Factuality in LLM Internal Representations  
**Servedio et al., May 2025**  
- Probes internal layers to understand how LLMs encode truth.  
- Links activation patterns to factual correctness.  
[arXiv:2505.16520](https://arxiv.org/abs/2505.16520)

---

### Scaling Reasoning Improves Factuality in Open-Domain QA  
**Zhang et al., May 2025**  
- Longer test-time reasoning leads to higher factual accuracy in QA.  
- Empirical gains of 2–8% via CoT prompting and scaling.  
[arXiv:2505.11140](https://arxiv.org/abs/2505.11140)

---

### Conformal Language Model Reasoning with Coherent Factuality Guarantees  
**Rubin-Toles et al., ICLR 2025**  
- Introduces a formal framework for “coherent factuality” using conformal prediction.  
- Achieves 90% verified factual accuracy in math reasoning tasks.  
(Forthcoming ICLR 2025)

---

### Two Birds with One Stone: Improving Factuality and Faithfulness via Dynamic Interactive Subspace Editing  
**Wang et al., June 2025**  
- Identifies and edits neural subspaces causing hallucination and faithfulness drift.  
- Presents unified mitigation strategy (SPACE).  
[arXiv:2506.11088](https://arxiv.org/abs/2506.11088)

---

## Ongoing Updates

This list is regularly updated. If you know of a 2025 paper on factuality not covered in the above surveys, feel free to open an issue or pull request.
