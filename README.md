#  Factuality in Large Language Models: Ongoing Survey Project

This is an **ongoing collection of research papers** related to **factuality in Large Language Models (LLMs)**.

📌 For brevity, individual papers from **before 2025** are not listed. Instead, we include two comprehensive survey papers covering those years. The list then focuses on **individual 2025 papers** that introduce new contributions beyond what these surveys cover.

---

## 📚 Survey Papers (Covering 2023–2024)

### 🔹 Yuxia Wang et al. (EMNLP 2024)  
**Factuality of Large Language Models: A Survey**  
Comprehensive taxonomy of factual errors, evaluation benchmarks, model behaviors, and mitigation strategies across 2023–2024 work.  
📄 [PDF](https://aclanthology.org/2024.emnlp-main.1088.pdf) | [arXiv](https://arxiv.org/abs/2310.07521)

### 🔹 Cunxiang Wang et al. (ACM Computing Surveys 2025) covers upto year 2023, although published in 2025
**Survey on Factuality in Large Language Models: Knowledge, Retrieval, and Domain-Specificity**  
Focuses on knowledge grounding, retrieval-augmented generation, domain-specific challenges, and factual consistency techniques.  
📄 [ResearchGate](https://www.researchgate.net/publication/392349351_Survey_on_Factuality_in_Large_Language_Models)

---

## 📝 2025 Papers (Not Covered in the Above Surveys)

### ✅ FactReasoner: Probabilistic Fact-Level Factuality Assessment for Long-Form LLM Outputs  
**Marinescu et al., Feb 2025**  
- Decomposes outputs into atomic facts and verifies them probabilistically.  
- Enables structured, interpretable factuality scoring.  
📄 [arXiv:2502.18573](https://arxiv.org/abs/2502.18573)

---

### ✅ Verify with Caution: The Pitfalls of Relying on Imperfect Factuality Metrics  
**Godbole & Jia, Jan 2025**  
- Empirical audit of 11 metrics across tasks; highlights inconsistencies.  
- Cautions against blind reliance on popular scoring methods.  
📄 [arXiv:2501.14883](https://arxiv.org/abs/2501.14883)

---

### ✅ Are the Hidden States Hiding Something? Investigating Factuality in LLM Internal Representations  
**Servedio et al., May 2025**  
- Probes internal layers to understand how LLMs encode truth.  
- Links activation patterns to factual correctness.  
📄 [arXiv:2505.16520](https://arxiv.org/abs/2505.16520)

---

### ✅ Scaling Reasoning Improves Factuality in Open-Domain QA  
**Zhang et al., May 2025**  
- Longer test-time reasoning leads to higher factual accuracy in QA.  
- Empirical gains of 2–8% via CoT prompting and scaling.  
📄 [arXiv:2505.11140](https://arxiv.org/abs/2505.11140)

---

### ✅ Conformal Language Model Reasoning with Coherent Factuality Guarantees  
**Rubin-Toles et al., ICLR 2025**  
- Introduces a formal framework for “coherent factuality” using conformal prediction.  
- Achieves 90% verified factual accuracy in math reasoning tasks.  
🔜 (Forthcoming ICLR 2025)

---

### ✅ Two Birds with One Stone: Improving Factuality and Faithfulness via Dynamic Interactive Subspace Editing  
**Wang et al., June 2025**  
- Identifies and edits neural subspaces causing hallucination and faithfulness drift.  
- Presents unified mitigation strategy (SPACE).  
📄 [arXiv:2506.11088](https://arxiv.org/abs/2506.11088)

---

## 🔄 Ongoing Updates

This list is regularly updated. If you know of a 2025 paper on factuality not covered in the above surveys, feel free to open an issue or pull request.

